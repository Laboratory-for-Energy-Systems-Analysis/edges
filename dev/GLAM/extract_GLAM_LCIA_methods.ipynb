{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T12:42:25.438181Z",
     "start_time": "2025-10-14T12:39:47.862747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === 1) Load EF→ecoinvent mapping (UUID -> {TargetFlowName, TargetFlowContext}) ===\n",
    "mapping_file = \"ILCD-EFv3.0-ecoinventEFv3.7.xlsx\"\n",
    "\n",
    "df_map = pd.read_excel(mapping_file)\n",
    "required_cols = [\"SourceFlowUUID\", \"TargetFlowName\", \"TargetFlowContext\"]\n",
    "for col in required_cols:\n",
    "    if col not in df_map.columns:\n",
    "        raise ValueError(f\"Missing required column in mapping file: {col}\")\n",
    "\n",
    "# Keep only rows with a non-empty TargetFlowName\n",
    "df_map = df_map.dropna(subset=[\"TargetFlowName\"])\n",
    "df_map = df_map[df_map[\"TargetFlowName\"].astype(str).str.strip() != \"\"]\n",
    "\n",
    "flow_dict = {\n",
    "    row[\"SourceFlowUUID\"]: {\n",
    "        \"TargetFlowName\": row[\"TargetFlowName\"],\n",
    "        \"TargetFlowContext\": row[\"TargetFlowContext\"],\n",
    "    }\n",
    "    for _, row in df_map.iterrows()\n",
    "}\n",
    "print(f\"✅ Loaded {len(flow_dict)} UUID mappings from {mapping_file}.\")\n",
    "\n",
    "# === 2) Walk through your folder structure and map per file (duplicates kept) ===\n",
    "root_folder = \".\"  # <- change this if needed\n",
    "\n",
    "results = {}                 # { filename: DataFrame with original + mapped columns }\n",
    "unmapped_per_file = {}       # { filename: set([uuid, ...]) }\n",
    "unmapped_rows = []           # list of DataFrames (unmapped rows with file column)\n",
    "stats_per_file = {}          # { filename: {'rows': int, 'matched': int, 'unmapped': int, 'pct': float} }\n",
    "\n",
    "for root, _, files in os.walk(root_folder):\n",
    "    for file in files:\n",
    "        if not file.endswith(('.xls', '.xlsx', '.xlsm')):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            xls = pd.ExcelFile(file_path)\n",
    "            if \"lciamethods_CF_GLAM\" not in xls.sheet_names:\n",
    "                print(f\"⚠️ Sheet 'lciamethods_CF_GLAM' not found in {file}\")\n",
    "                continue\n",
    "\n",
    "            # Desired columns (keep forgiving behavior)\n",
    "            desired_usecols = [\n",
    "                \"FLOW_uuid\", \"FLOW_name\",\n",
    "                \"FLOW_class0\", \"FLOW_class1\", \"FLOW_class2\",\n",
    "                \"CF\", \"Unit\", \"CF_Uncertainty_Lower\", \"CF_Uncertainty_Higher\",\n",
    "                \"LCIAMethod_location_ISO2\", \"LCIAMethod_type\"\n",
    "            ]\n",
    "\n",
    "            df_full = pd.read_excel(file_path, sheet_name=\"lciamethods_CF_GLAM\")\n",
    "            present_cols = [c for c in desired_usecols if c in df_full.columns]\n",
    "            missing_cols = [c for c in desired_usecols if c not in df_full.columns]\n",
    "            if missing_cols:\n",
    "                print(f\"ℹ️ {file}: missing columns skipped: {missing_cols}\")\n",
    "\n",
    "            if \"FLOW_uuid\" not in df_full.columns:\n",
    "                print(f\"⚠️ No 'FLOW_uuid' column in {file}\")\n",
    "                continue\n",
    "\n",
    "            df = df_full[present_cols].copy()\n",
    "\n",
    "            # Normalize and clean UUIDs\n",
    "            df[\"FLOW_uuid\"] = df[\"FLOW_uuid\"].astype(str).str.strip()\n",
    "            df = df[df[\"FLOW_uuid\"] != \"\"].dropna(subset=[\"FLOW_uuid\"])\n",
    "            df = df[df[\"FLOW_name\"] != \"\"].dropna(subset=[\"FLOW_name\"])\n",
    "\n",
    "            # Map columns from flow_dict (preserve duplicates)\n",
    "            df[\"TargetFlowName\"] = df[\"FLOW_uuid\"].map(lambda x: flow_dict.get(x, {}).get(\"TargetFlowName\"))\n",
    "            df[\"TargetFlowContext\"] = df[\"FLOW_uuid\"].map(lambda x: flow_dict.get(x, {}).get(\"TargetFlowContext\"))\n",
    "\n",
    "            # remove rows where mapping failed (optional)\n",
    "            df = df.dropna(subset=[\"TargetFlowName\"])\n",
    "            df = df[df[\"TargetFlowName\"] != \"\"].dropna(subset=[\"TargetFlowName\"])\n",
    "\n",
    "            # Stats per file\n",
    "            total_rows = len(df)\n",
    "            unmapped_rows_count = int(df[\"TargetFlowName\"].isna().sum())\n",
    "            matched_rows_count = total_rows - unmapped_rows_count\n",
    "            pct_matched = (matched_rows_count / total_rows * 100.0) if total_rows else 0.0\n",
    "            stats_per_file[file] = {\n",
    "                \"rows\": total_rows,\n",
    "                \"matched\": matched_rows_count,\n",
    "                \"unmapped\": unmapped_rows_count,\n",
    "                \"pct\": pct_matched,\n",
    "            }\n",
    "\n",
    "            # Identify unmapped rows (all occurrences)\n",
    "            missing_mask = df[\"TargetFlowName\"].isna()\n",
    "            if missing_mask.any():\n",
    "                unmapped_per_file[file] = set(df.loc[missing_mask, \"FLOW_uuid\"].unique())\n",
    "                df_unmapped = df.loc[missing_mask].copy()\n",
    "                df_unmapped[\"file\"] = file\n",
    "                unmapped_rows.append(df_unmapped)\n",
    "\n",
    "            # Store DataFrame for Excel export\n",
    "            results[file] = df\n",
    "\n",
    "        except KeyError as ke:\n",
    "            print(f\"❌ Missing expected column in {file}: {ke}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {file}: {e}\")\n",
    "\n",
    "# === 3) Summary (with per-file % matched) ===\n",
    "print(\"\\n✅ Mapping results summary:\")\n",
    "total_files = len(results)\n",
    "total_rows = sum(s[\"rows\"] for s in stats_per_file.values())\n",
    "total_matched = sum(s[\"matched\"] for s in stats_per_file.values())\n",
    "total_unmapped = sum(s[\"unmapped\"] for s in stats_per_file.values())\n",
    "overall_pct = (total_matched / total_rows * 100.0) if total_rows else 0.0\n",
    "\n",
    "print(f\"- Files processed: {total_files}\")\n",
    "print(f\"- Total rows processed (duplicates kept): {total_rows}\")\n",
    "print(f\"- Matched rows: {total_matched}\")\n",
    "print(f\"- Unmapped rows: {total_unmapped}\")\n",
    "print(f\"- Overall match rate: {overall_pct:.2f}%\")\n",
    "\n",
    "print(\"\\n📊 Per-file match rate:\")\n",
    "for fname, s in sorted(stats_per_file.items()):\n",
    "    print(f\"  {fname}: {s['matched']}/{s['rows']} rows matched ({s['pct']:.2f}%)\")\n",
    "\n",
    "if unmapped_per_file:\n",
    "    print(\"\\n🔎 Unmapped UUIDs per file (unique counts):\")\n",
    "    for fname, s in sorted(unmapped_per_file.items()):\n",
    "        print(f\"  {fname}: {len(s)}\")\n",
    "else:\n",
    "    print(\"\\n🎉 No unmapped UUIDs found.\")\n",
    "\n",
    "# === 4) Export details of unmapped rows (CSV) ===\n",
    "df_unmapped_all = None\n",
    "if unmapped_rows:\n",
    "    df_unmapped_all = pd.concat(unmapped_rows, ignore_index=True)\n",
    "    df_unmapped_all = df_unmapped_all.sort_values([\"file\", \"FLOW_uuid\"])\n",
    "    df_unmapped_all.to_csv(\"unmapped_flows.csv\", index=False)\n",
    "    print(\"\\n💾 Wrote details of unmapped rows to 'unmapped_flows.csv'.\")\n",
    "\n",
    "# === 5) Export all per-file results to Excel ===\n",
    "output_file = \"flow_mapping_results.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    # One sheet per processed file\n",
    "    for fname, df_out in results.items():\n",
    "        sheet_name = os.path.splitext(fname)[0][:31]  # Excel sheet name limit\n",
    "        df_out.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "    # Include a global Unmapped sheet inside the same workbook\n",
    "    if df_unmapped_all is not None and not df_unmapped_all.empty:\n",
    "        df_unmapped_all.to_excel(writer, index=False, sheet_name=\"Unmapped_Flows\")\n",
    "\n",
    "    # (Optional) also include a Summary sheet with per-file stats\n",
    "    summary_rows = [\n",
    "        {\"file\": f, \"rows\": s[\"rows\"], \"matched\": s[\"matched\"], \"unmapped\": s[\"unmapped\"], \"match_%\": s[\"pct\"]}\n",
    "        for f, s in sorted(stats_per_file.items())\n",
    "    ]\n",
    "    if summary_rows:\n",
    "        df_summary = pd.DataFrame(summary_rows)\n",
    "        df_summary.to_excel(writer, index=False, sheet_name=\"Summary\")\n",
    "\n",
    "print(f\"\\n💾 Exported all mapping results to '{output_file}'\")\n"
   ],
   "id": "deb5cbbbb26f2b63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 22104 UUID mappings from ILCD-EFv3.0-ecoinventEFv3.7.xlsx.\n",
      "❌ Error reading ~$flow_mapping_results.xlsx: Excel file format cannot be determined, you must specify an engine manually.\n",
      "⚠️ Sheet 'lciamethods_CF_GLAM' not found in ILCD-EFv3.0-ecoinventEFv3.7.xlsx\n",
      "⚠️ Sheet 'lciamethods_CF_GLAM' not found in flow_mapping_results.xlsx\n",
      "\n",
      "✅ Mapping results summary:\n",
      "- Files processed: 23\n",
      "- Total rows processed (duplicates kept): 278827\n",
      "- Matched rows: 278827\n",
      "- Unmapped rows: 0\n",
      "- Overall match rate: 100.00%\n",
      "\n",
      "📊 Per-file match rate:\n",
      "  GLAM_template_EQ_Aquatic_Microplastics.xlsx: 0/0 rows matched (0.00%)\n",
      "  GLAM_template_EQ_Climate_Change_FW_TR_MA.xlsx: 99/99 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Ecotoxicity_FW.xlsx: 20404/20404 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Ecotoxicity_TR.xlsx: 2842/2842 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Freshwater_Eutrophication.xlsx: 6183/6183 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Land_Use.xlsx: 32085/32085 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Marine_Eutrophication.xlsx: 5531/5531 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Terrestrial_Acidification.xlsx: 828/828 rows matched (100.00%)\n",
      "  GLAM_template_EQ_Water_Consumption.xlsx: 1859/1859 rows matched (100.00%)\n",
      "  GLAM_template_HH_Climate_Change.xlsx: 68/68 rows matched (100.00%)\n",
      "  GLAM_template_HH_Fine_Particulate_Matter_Impacts.xlsx: 11229/11229 rows matched (100.00%)\n",
      "  GLAM_template_HH_Human_Toxicity.xlsx: 16662/16662 rows matched (100.00%)\n",
      "  GLAM_template_HH_Ionizing_Radiation.xlsx: 366/366 rows matched (100.00%)\n",
      "  GLAM_template_HH_Lifestyle_Impacts_Nutrition.xlsx: 0/0 rows matched (0.00%)\n",
      "  GLAM_template_HH_Lifestyle_Impacts_Physical_activity.xlsx: 0/0 rows matched (0.00%)\n",
      "  GLAM_template_HH_Water_Scarcity.xlsx: 2079/2079 rows matched (100.00%)\n",
      "  GLAM_template_HH_Work_Environment_Impacts.xlsx: 0/0 rows matched (0.00%)\n",
      "  GLAM_template_SEA_Abiotic energy_Mineral_resource_use.xlsx: 42/42 rows matched (100.00%)\n",
      "  GLAM_template_SEA_Land_Use_Erosion_Resistance.xlsx: 37932/37932 rows matched (100.00%)\n",
      "  GLAM_template_SEA_Land_Use_Groundwater_Regeneration.xlsx: 40412/40412 rows matched (100.00%)\n",
      "  GLAM_template_SEA_Land_Use_Mechanical_Filtration.xlsx: 41260/41260 rows matched (100.00%)\n",
      "  GLAM_template_SEA_Land_Use_Physiochemical_Filtration.xlsx: 20770/20770 rows matched (100.00%)\n",
      "  GLAM_template_SEA_Land_Use_Soil_Organic_Carbon.xlsx: 38176/38176 rows matched (100.00%)\n",
      "\n",
      "🎉 No unmapped UUIDs found.\n",
      "\n",
      "💾 Exported all mapping results to 'flow_mapping_results.xlsx'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "879878f441ea6d58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
